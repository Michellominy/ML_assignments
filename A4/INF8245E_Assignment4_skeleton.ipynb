{"cells":[{"cell_type":"markdown","metadata":{"id":"5GrDrzYSM41S"},"source":["# Assignment 4\n","\n","## Instructions\n","This is an individual assignment. You are not allowed to discuss the problems with other students.\n","\n","- Part of this assignment will be autograded by Gradescope. You can use it as immediate feedback to improve your answers. You can resubmit as many times as you want. We provide some tests which you can use to check that your code will execute properly on Gradescope. These are **not** meant to check the correctness of your answers. We encourage you to write your own tests for this.\n","- All your code, analysis, graphs, explanations, etc. should be done in this same notebook.\n","- Please make sure to execute all the cells before you export the notebook to a PDF and submit it to Gradescope. You will not get points for the plots if they are not generated already.\n","- If you have questions regarding the assignment, you can ask for clarifications in Piazza. You should use the corresponding tag for this assignment.\n","\n","Before starting the assignment, make sure that you have downloaded all the data and tests related for the assignment and put them in the appropriate locations. If you run the next cell, we will set this all up automatically for you in a dataset called public, which will contain both the data and tests you use.\n","\n","**Warning**: Throughout the assignment, you will be asked to implement certain algorithms and find optimal values. In the solution you submit, do not simply call a library function which performs the entire algorithm for you, this is forbidden, as it would obviously defeat the purpose. For example, if you were asked to implement the linear regression, do not simply call an outside package for help.\n","\n","**When Submitting to GradeScope**: Be sure to\n","1) Submit a `.ipynb` notebook to the `Assignment 4 - Practical` section on Gradescope.\n","2) Submit a `pdf` version of the notebook to the `Assignment 4 - Analysis` entry.\n","\n","**Note**: You can choose to submit responses in either English or French."]},{"cell_type":"code","execution_count":36,"metadata":{"id":"lsP4ASLXLVjG"},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n","fatal: destination path 'public' already exists and is not an empty directory.\n"]}],"source":["!pip install -q otter-grader\n","!git clone https://github.com/chandar-lab/INF8245e-assignments-2023.git public"]},{"cell_type":"markdown","metadata":{"id":"02eg8tx8zeDD"},"source":["In this assignment, we will walk you through the steps of implement a simple neural network with all necessary components. You will attempt to replicate your own version of _PyTorch_ by defining minimalistic clases which ressemble the famous deep learning library.\n","\n","![](https://drive.google.com/uc?export=view&id=1RRxUje8FRJFDcAfIxyA9WBrphgq96Q-X)\n","\n","You will implement commonly used activation functions such as `softmax`, `tanh`, and `relu`, and loss fuction such as `cross entropy`. For each activation layer, you will implement the forward and backward pass by computing the gradient. Finally, you will put everything together in a training loop and train it on the MNIST dataset of hand-written digits.\n","\n"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"1g-g2XcOy1IK"},"outputs":[],"source":["# DO NOT RE-SEED ANYWHERE OTHERWISE YOUR IMPLEMENTATION MAY FAIL SOME UNIT TESTS\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from typing import List, Tuple, Union, Dict, Callable\n","\n","np.random.seed(8245)\n","\n","%matplotlib inline\n","\n","working_dir = './A4' #  TO THECHANGE THIS MAIN ASSIGNMENT DIRECTORY"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"tc32wN9erB_H"},"outputs":[{"name":"stdout","output_type":"stream","text":["c:\\Users\\Michel\\Desktop\\POLY\\automne_2023\\INF8245E\\Lab\\ML_assignments\\A4\\public\\a4\\public\\a4\\public\\a4\n"]}],"source":["%cd public/a4"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"AVDOncNAjlV-"},"outputs":[],"source":["# Initialize Otter\n","import otter\n","\n","os.makedirs(\"tests\", exist_ok=True)\n","\n","grader = otter.Notebook(colab=True, tests_dir='./tests')"]},{"cell_type":"markdown","metadata":{"id":"BIwtL9l7M9ty"},"source":["## **Question 1: Layer Classes (12 points)**\n"]},{"cell_type":"markdown","metadata":{"id":"YAxTCzVaBmWZ"},"source":["The following class `Layer` is a super-class from which subsequent layer, activation, and loss classes will be inherited. Nothing needs to be changed here, but it's good to get familiar with the stucture and the instuctions."]},{"cell_type":"code","execution_count":40,"metadata":{"id":"tIIXAW9SPQKx"},"outputs":[],"source":["class Layer:\n","    \"\"\"\n","    Base class for all layers.\n","    \"\"\"\n","    def __init__(self):\n","        \"\"\"\n","        Initialize layer parameters (if any) and auxiliary data that is needed for,\n","        usually, variables like input_size, output_size, are initialized here.\n","        \"\"\"\n","\n","    def init_weights(self):\n","        \"\"\"\n","        Initialize the weights of the layer, if applicable.\n","        \"\"\"\n","        pass\n","\n","    def forward(self, input):\n","        \"\"\"\n","        Forward pass of the layer.\n","        Parameter:\n","            input: input data\n","        Returns:\n","            output: output of the layer\n","        \"\"\"\n","        pass\n","\n","    def backward(self, output_grad):\n","        \"\"\"\n","        Backward pass of the layer.\n","        Parameter:\n","            output_grad: gradient of the output of the layer (dy)\n","        Returns:\n","            input_grad: gradient of the input of the layer (dx)\n","        \"\"\"\n","        pass\n","\n","    def update(self, learning_rate):\n","        \"\"\"\n","        Update the layer parameters, if applicable.\n","        Parameter:\n","            learning_rate: learning rate used for updating\n","        \"\"\"\n","        pass"]},{"cell_type":"markdown","metadata":{"id":"k7HylSdX7sQ9"},"source":["### Q1 a) **(10 points)**\n"]},{"cell_type":"markdown","metadata":{"id":"Mf1dt897VTcW"},"source":["Follow the instuctions in the comments, implement a fully-connected layer (`Dense`) capable of working with any generic input and output sizes. It should define its weight and bias matrices inside.\n","\n"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"nPbuNuCf7k0O","tags":[]},"outputs":[],"source":["class Dense(Layer):\n","    \"\"\"\n","    Fully connected layer.\n","    \"\"\"\n","    def __init__(\n","        self,\n","        input_size,\n","        output_size,\n","        weights=None,\n","        bias=None\n","    ):\n","        \"\"\"\n","        Initialize the layer.\n","        Parameters:\n","            input_size (int): input size of the layer\n","            output_size (int): output size of the layer\n","            weights (np.ndarray): weights of the layer\n","            bias (np.ndarray): bias of the layer\n","        \"\"\"\n","        super().__init__()\n","        self.input_size = input_size\n","        self.output_size = output_size\n","        self.init_weights(weights=weights, bias=bias)\n","\n","    def init_weights(self, weights=None, bias=None):\n","        \"\"\"\n","        Initializes the weights of the layer.\n","        If weights and bias are not provided, they are initialized\n","        with a Gaussian N(0, 1) random values and zeros, respectively.\n","        Parameters:\n","            weights (np.ndarray): weights of the layer, shape: (self.input_size, self.output_size)\n","            bias (np.ndarray): bias of the layer, shape: (1, self.output_size)\n","        \"\"\"\n","        if weights is None:\n","            self.weights = np.random.normal(0, 1, (self.input_size, self.output_size))\n","        else:\n","            self.weights = weights\n","\n","        if bias is None:\n","            self.bias = np.zeros((1, self.output_size))  # Initialize biases with zeros\n","        else:\n","            self.bias = bias\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass of the layer.\n","        Parameters:\n","            x (np.ndarray): input of the layer, shape: (batch_size, self.input_size)\n","        Returns:\n","            output (np.ndarray): output of the layer, shape: (batch_size, self.output_size)\n","        \"\"\"\n","        self.input = x\n","        self.output = np.dot(x, self.weights) + self.bias\n","        return self.output\n","\n","    def backward(self, output_grad):\n","        \"\"\"\n","        Backward pass of the layer.\n","        Parameters:\n","            output_grad (np.ndarray): gradient of the output of the layer (dy), shape: (batch_size, self.output_size)\n","        Returns:\n","            input_grad (np.ndarray): gradient of the input of the layer (dx), shape: (batch_size, self.input_size)\n","        \"\"\"\n","        self.weights_grad = np.dot(self.input.T, output_grad)\n","        self.bias_grad = np.sum(output_grad, axis=0, keepdims=True)\n","        self.input_grad = np.dot(output_grad, self.weights.T)\n","        return self.input_grad\n","    \n","    def update(self, learning_rate):\n","        \"\"\"\n","        Update the layer parameters. Normally, this is done by using the\n","        gradients computed in the backward pass; therefore, backward() must\n","        be called before update().\n","        This function implements SGD (stochastic gradient descent)\n","        Parameter:\n","            learning_rate (float): learning rate used for updating\n","        \"\"\"\n","        # assumes self.backward() function has been called before\n","        assert hasattr(self, 'weights_grad'), \\\n","            'must compute gradient of weights before'\n","        assert hasattr(self, 'bias_grad'), \\\n","            'must compute gradient of bias before'\n","        self.weights -= learning_rate * self.weights_grad\n","        self.bias -= learning_rate * self.bias_grad\n"]},{"cell_type":"code","execution_count":42,"metadata":{"deletable":false,"editable":false,"id":"2tl7UDyf6NVe"},"outputs":[{"data":{"text/html":["<p><strong><pre style='display: inline;'>q1.1</pre></strong> passed! 🚀</p>"],"text/plain":["q1.1 results: All test cases passed!"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["grader.check(\"q1.1\")"]},{"cell_type":"markdown","metadata":{"id":"j9h44ZdmGfGD"},"source":["### Q1 b) **(2 points)**\n","\n","- In one or two sentences, what is the purpose of bias variables?\n","- In one or two sentences, what is the purpose of activation functions in neural networks, and why are they important?"]},{"cell_type":"markdown","metadata":{"id":"1l3shw0U6NVe"},"source":["_Type your answer here, replacing this text._"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"7MvrhYkj4F_U"},"source":["<!-- END QUESTION -->\n","\n","## **Question 2: Activation and Loss Layers (20 points)**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Yg-74JudCa0o"},"source":["### Q2 a) **(15 points)**\n","\n","Implement the forward pass for `softmax`, `tanh`, and `relu` layers. The forward pass fuction receives the input data (usually a vector or a tensor) from the previous layer, and applies the activation function element-wise to the input data to compute the output of the activation layer.  \n","\n","(We will come back to implementing the backward pass later as well.)\n"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"LlpLVpxm8N6H","tags":[]},"outputs":[],"source":["class SoftmaxLayer(Layer):\n","    \"\"\"\n","    Softmax layer.\n","    \"\"\"\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass of the layer.\n","        The output's sum along the second axis should be 1.\n","        Parameter:\n","            x (np.ndarray): input of the layer, shape: (batch_size, input_size)\n","        Returns:\n","            output (np.ndarray): output of the layer, shape: (batch_size, input_size)\n","        \"\"\"\n","        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n","        self.output = exp_x / np.sum(exp_x, axis=1, keepdims=True)\n","        return self.output\n","\n","\n","    def backward(self, output_grad):\n","        \"\"\"\n","        Backward pass of the layer.\n","        Parameter:\n","            output_grad (np.ndarray): gradient of the output of the layer (dy), shape: (batch_size, input_size)\n","        Returns:\n","            input_grad (np.ndarray): gradient of the input of the layer (dx), shape: (batch_size, input_size)\n","        \"\"\"\n","        self.input_grad = self.output * (output_grad - np.sum(self.output * output_grad, axis=1, keepdims=True))\n","        return self.input_grad\n","\n","\n","class TanhLayer(Layer):\n","    \"\"\"\n","    Tanh layer.\n","    \"\"\"\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass of the layer.\n","        Parameter:\n","            x (np.ndarray): input of the layer, shape: (batch_size, input_size)\n","        Returns:\n","            output (np.ndarray): output of the layer, shape: (batch_size, input_size)\n","        \"\"\"\n","        self.input = x\n","        self.output = np.tanh(x)\n","        return self.output\n","\n","    def backward(self, output_grad):\n","        \"\"\"\n","        Backward pass of the layer.\n","        Parameter:\n","            output_grad (np.ndarray): gradient of the output of the layer (dy), shape: (batch_size, input_size)\n","        Returns:\n","            input_grad (np.ndarray): gradient of the input of the layer (dx), shape: (batch_size, input_size)\n","        \"\"\"\n","        self.input_grad = output_grad * (1 - np.tanh(self.input)**2)\n","        return self.input_grad\n","\n","\n","class ReLULayer(Layer):\n","    \"\"\"\n","    ReLU layer.\n","    \"\"\"\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass of the layer.\n","        Parameter:\n","            x (np.ndarray): input of the layer, shape: (batch_size, input_size)\n","        Returns:\n","            output (np.ndarray): output of the layer, shape: (batch_size, input_size)\n","        \"\"\"\n","        self.output = np.maximum(0, x)\n","        return self.output\n","\n","    def backward(self, output_grad):\n","        \"\"\"\n","        Backward pass of the layer.\n","        Parameter:\n","            output_grad (np.ndarray): gradient of the output of the layer (dy), shape: (batch_size, input_size)\n","        Returns:\n","            input_grad (np.ndarray): gradient of the input of the layer (dx), shape: (batch_size, input_size)\n","        \"\"\"\n","        self.input_grad = output_grad * (self.output > 0)\n","        return self.input_grad\n"]},{"cell_type":"code","execution_count":44,"metadata":{"deletable":false,"editable":false,"id":"yDMxdxkv6NVf"},"outputs":[{"data":{"text/html":["<p><strong><pre style='display: inline;'>q2.1</pre></strong> passed! 💯</p>"],"text/plain":["q2.1 results: All test cases passed!"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["grader.check(\"q2.1\")"]},{"cell_type":"markdown","metadata":{"id":"ZN7gS9Bq4P-R"},"source":["### Q2 b) **(5 points)**\n","Now, implement a cross-entropy loss layer.\n","\n","The forward pass again receives the predicted class probabilities (output from a previous activation layer) and the ground truth labels (target). It computes the cross-entropy loss using the predicted probabilities and the ground truth labels. The loss function measures the dissimilarity between the predicted probabilities and the actual labels.\n","\n","In the backward pass, you need to compute the gradient of the loss with respect to the predicted probabilities. This gradient will be used to update the weights and biases of the preceding layers during backpropagation.\n","\n","The equation for the cross-entropy loss is given by:\n","$$\n","\\mathcal{L} = -\\sum_{i=1}^{N} y_i \\log(p_i)\n","$$\n","where $y_i$ is the ground truth label, $p_i$ is the predicted probability for class $i$, and $N$ is the number of classes.\n","\n","Note that here we are NOT averaging the loss over the batch, so the loss is simply the sum of the losses for each sample in the batch; therefore, for the purposes of this assignment, dividing by the batch size might cause failures while testing your code. In deep learning libraries, such as PyTorch, choosing whether to average the loss over the batch or not is a parameter that can be set by the user; yet this assignment does not require you to implement this functionality.\n","\n","The `.forward()` function receives two parameters:\n","- `prediction`: the predicted class **probabilities** (output from a previous activation layer), of shape `(batch_size, num_classes)`. Therefore, each row should sum to 1.\n","- `target`: the ground truth labels, of shape `(batch_size, )`. Each element is an integer between 0 and `num_classes - 1`.\n","\n","Finally, to handle numerical stability, it is a good practice to add a small value (e.g. $10^{-10}$) to the predicted probabilities before taking the logarithm.\n"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"co9R9f1lQ6EC","tags":[]},"outputs":[],"source":["class CrossEntropyLossLayer(Layer):\n","    \"\"\"\n","    Cross entropy loss layer.\n","    \"\"\"\n","\n","    def forward(self, prediction, target):\n","        \"\"\"\n","        Forward pass of the layer.\n","        Note that prediction input is assumed to be a probability distribution (e.g., softmax output).\n","        Parameters:\n","            prediction (np.ndarray): prediction of the model, shape: (batch_size, num_classes)\n","            target (np.ndarray): target, shape: (batch_size,)\n","        Returns:\n","            output (float): cross entropy loss, averaged over the batch\n","        \"\"\"\n","        self.batch_size = prediction.shape[0]\n","        self.prediction = prediction\n","        self.target = target\n","\n","        epsilon = 1e-10\n","        prediction = np.clip(prediction, epsilon, 1 - epsilon)\n","        cross_entropy_loss = -np.sum(np.log(prediction[np.arange(self.batch_size), target]))\n","        return cross_entropy_loss\n","\n","    def backward(self, output_grad):\n","        \"\"\"\n","        Backward pass of the layer.\n","        Parameter:\n","            output_grad (float): gradient of the output of the layer (dy)\n","        Returns:\n","            input_grad (np.ndarray): gradient of the input of the layer (dx), shape: (batch_size, num_classes)\n","        \"\"\"\n","        input_grad = np.zeros_like(self.prediction)\n","        input_grad[np.arange(self.batch_size), self.target] = -1 / (self.prediction[np.arange(self.batch_size), self.target])\n","        input_grad *= output_grad\n","        return input_grad\n"]},{"cell_type":"code","execution_count":46,"metadata":{"deletable":false,"editable":false,"id":"UrOVzYxU6NVg"},"outputs":[{"data":{"text/html":["<p><strong><pre style='display: inline;'>q2.2</pre></strong> passed! 🚀</p>"],"text/plain":["q2.2 results: All test cases passed!"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["grader.check(\"q2.2\")"]},{"cell_type":"markdown","metadata":{"id":"mdc_6FiR6Q_Y"},"source":["## **Question 3: Putting it all together: MLP (5 points)**\n","\n","Now, we will put everything together and implement an MLP (multi-layer perceptron) class which is capable enough of stacking multiple layers."]},{"cell_type":"markdown","metadata":{"id":"3e_rkjwrC14U"},"source":["### Q3 a) **(5 points)**\n","\n","Implement a multi-layer perceptron class (`MLP`) capable of stacking multiple layers."]},{"cell_type":"code","execution_count":47,"metadata":{"id":"gIujgVk4iY9z","tags":[]},"outputs":[],"source":["class MLP(Layer):\n","    \"\"\"\n","    Multi-layer perceptron.\n","    \"\"\"\n","    def __init__(self, layers):\n","        \"\"\"\n","        Initialize the MLP. The passed list of layers usually\n","        follows the order: [Dense, Activation, Dense, Activation, ...]\n","        Parameters:\n","            layers (list): list of layers of the MLP\n","        \"\"\"\n","        super().__init__()\n","        self.layers = layers\n","\n","    def forward(self, input):\n","        \"\"\"\n","        Forward pass of the MLP.\n","        Go over each layers sequentially and call their .forward() function.\n","        Don't forget to store every intermediate results in order to use them\n","        in the backward pass.\n","        Parameter:\n","            input (np.ndarray): input of the MLP, shape: (batch_size, input_size)\n","                                (NOTE: input_size is the size of the input of the first layer)\n","        Returns:\n","            output (np.ndarray): output of the MLP, shape: (batch_size, output_size)\n","                                 (NOTE: output_size is the size of the output of the last layer)\n","        \"\"\"\n","        self.layer_inputs = [input]\n","        for layer in self.layers:\n","            input = layer.forward(input)\n","            self.layer_inputs.append(input)\n","        return input\n","\n","    def backward(self, output_grad):\n","        \"\"\"\n","        Backward pass of the MLP.\n","        Go over each layers in reverse order and call their .backward() function.\n","        Make sure to pass the correct gradient to each layer.\n","        Parameter:\n","            output_grad (np.ndarray): gradient of the output of the MLP (dy)\n","        Returns:\n","            input_grad (np.ndarray): gradient of the input of the MLP (dx)\n","        \"\"\"\n","        self.layer_grads = [output_grad]\n","        for i in range(len(self.layers) - 1, -1, -1):\n","            output_grad = self.layers[i].backward(output_grad)\n","            self.layer_grads.insert(0, output_grad)\n","        return output_grad\n","\n","    def update(self, learning_rate):\n","        \"\"\"\n","        Update the MLP parameters. Normally, this is done by using the\n","        gradients computed in the backward pass; therefore, .backward() must\n","        be called before update().\n","        Parameter:\n","            learning_rate (float): learning rate used for updating\n","        \"\"\"\n","        # assumes self.backward() function has been called before\n","        assert hasattr(self, 'layer_grads'), \\\n","            'must compute gradient of weights beforehand'\n","        for i in range(len(self.layers)):\n","            self.layers[i].update(learning_rate)\n"]},{"cell_type":"code","execution_count":48,"metadata":{"deletable":false,"editable":false,"id":"INMps86i6NVh"},"outputs":[{"data":{"text/html":["<p><strong><pre style='display: inline;'>q3.1</pre></strong> passed! 🚀</p>"],"text/plain":["q3.1 results: All test cases passed!"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["grader.check(\"q3.1\")"]},{"cell_type":"markdown","metadata":{"id":"V9m3vNmiO7XE"},"source":["## **Question 4: Training loop (10 points)**\n","\n","Ta-ta! We have now build a neural network from scratch, and it is ready to be trained. We will train the neural network on the MNIST dataset consists of hand-written digits. You don't have to change the implementation for this part."]},{"cell_type":"markdown","metadata":{"id":"3eLb6XIGEosh"},"source":["### Q4 a) **(10 points)**\n","\n","We now provide a training loop for you to observe your implementation in action. You should see this part deliver the expected behavior if you have implemented everything correctly. The provided code behaves as follows:\n","\n","1. Loads the MNIST dataset.\n","2. Visualizes some samples from the dataset.\n","3. $\\to$ Initializes the neural network.\n","4. $\\to$ Trains the neural network for 20 epochs.\n","5. $\\to$ Evaluates the neural network on the test set.\n","6. $\\to$ Plots the training loss and accuracy.\n","\n","Your implementation impacts the previous points preceded by a $\\to$. At the end, you should see a plot of the training loss and accuracy. The loss should decrease and the accuracy should increase as the training progresses.\n","\n","**Please DO NOT modify the following training scripts.**\n","\n","Even though the curious programmer would want to play with the hyperparameters, we ask you to keep them as they are for the sake of the grading process."]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"jmDUHKc_6NVi"},"source":["<!-- BEGIN QUESTION -->\n","\n"]},{"cell_type":"code","execution_count":49,"metadata":{"deletable":false,"editable":false,"id":"J1PkJFnma8oA"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.datasets import load_digits\n","from sklearn.model_selection import train_test_split\n","from tqdm.auto import tqdm"]},{"cell_type":"code","execution_count":50,"metadata":{"deletable":false,"editable":false,"id":"s1syCiexbHf5"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1200x300 with 5 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# set experiment's random seed\n","generator = np.random.default_rng(8249)\n","\n","# Load the minimalistic MNIST dataset using scikit-learn\n","mnist = load_digits()\n","data, labels = mnist.data, mnist.target\n","\n","# Split the dataset into training and testing sets\n","train_images, test_images, train_labels, test_labels = train_test_split(\n","    data,\n","    labels,\n","    test_size=0.2,\n","    random_state=8249\n",")\n","\n","# We visualize some digits\n","num_digits_to_visualize = 5\n","\n","# Create subplots to display the digits\n","fig, axes = plt.subplots(1, num_digits_to_visualize, figsize=(12, 3))\n","\n","for i, img_idx in enumerate(generator.integers(\n","    low=0,\n","    high=train_images.shape[0],\n","    size=num_digits_to_visualize\n",")):\n","    # Reshape the flattened image data back to 28x28\n","    digit_image = train_images[img_idx].reshape(8, 8)\n","\n","    # Display the digit image\n","    axes[i].imshow(digit_image, cmap='gray')\n","    axes[i].set_title(f\"Label: {labels[img_idx]}\")\n","    axes[i].axis('off')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":51,"metadata":{"deletable":false,"editable":false,"id":"Xq0biKsbbK9K"},"outputs":[],"source":["# Define a simple MLP model\n","input_size = 64\n","hidden_size = 128\n","output_size = 10\n","\n","# initialize weights using Xavier initialization\n","W_1 = generator.normal(0, 1, (input_size, hidden_size)) * np.sqrt(1 / input_size)\n","b_1 = np.zeros((1, hidden_size))\n","W_2 = generator.normal(0, 1, (hidden_size, output_size)) * np.sqrt(1 / hidden_size)\n","b_2 = np.zeros((1, output_size))\n","\n","mlp = MLP([\n","    Dense(input_size, hidden_size, weights=W_1, bias=b_1),\n","    TanhLayer(),\n","    Dense(hidden_size, output_size, weights=W_2, bias=b_2),\n","    SoftmaxLayer()\n","])\n","\n","# Define a cross-entropy loss layer\n","cross_entropy_layer = CrossEntropyLossLayer()"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"LSVhgDTDbQmP","tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"28eda3950ee84c6fb9870438e47c8c82","version_major":2,"version_minor":0},"text/plain":["Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Michel\\AppData\\Local\\Temp\\ipykernel_3448\\3589144208.py:34: RuntimeWarning: divide by zero encountered in divide\n","  input_grad[np.arange(self.batch_size), self.target] = -1 / (self.prediction[np.arange(self.batch_size), self.target])\n","C:\\Users\\Michel\\AppData\\Local\\Temp\\ipykernel_3448\\3589144208.py:34: RuntimeWarning: overflow encountered in divide\n","  input_grad[np.arange(self.batch_size), self.target] = -1 / (self.prediction[np.arange(self.batch_size), self.target])\n","C:\\Users\\Michel\\AppData\\Local\\Temp\\ipykernel_3448\\297171637.py:27: RuntimeWarning: invalid value encountered in multiply\n","  self.input_grad = self.output * (output_grad - np.sum(self.output * output_grad, axis=1, keepdims=True))\n","C:\\Users\\Michel\\AppData\\Local\\Temp\\ipykernel_3448\\297171637.py:27: RuntimeWarning: invalid value encountered in subtract\n","  self.input_grad = self.output * (output_grad - np.sum(self.output * output_grad, axis=1, keepdims=True))\n"]},{"name":"stdout","output_type":"stream","text":["Training complete.\n","Test accuracy: 10.00%\n"]}],"source":["# Training parameters\n","learning_rate = 0.1\n","epochs = 20\n","batch_size = 128\n","\n","# Training loop\n","epoch_bar = tqdm(range(epochs), desc='Epoch')\n","train_accuracies = []\n","train_losses = []\n","for epoch in epoch_bar:\n","    step_accuracies = []\n","    step_losses = []\n","    for step, i in enumerate(range(0, len(train_images), batch_size)):\n","        # Prepare the batch\n","        batch_images = train_images[i:i + batch_size]\n","        batch_labels = train_labels[i:i + batch_size]\n","\n","        # Forward pass\n","        output = mlp.forward(batch_images)\n","        loss = cross_entropy_layer.forward(output, batch_labels)\n","\n","        # Backward pass\n","        loss_grad = cross_entropy_layer.backward(loss)\n","        mlp.backward(loss_grad)\n","        mlp.update(learning_rate)\n","\n","        # train accuracy\n","        total = len(batch_images)\n","        predictions = np.argmax(output, axis=1)\n","        correct = np.sum(predictions == batch_labels)\n","        accuracy = correct / total\n","        step_accuracies.append(accuracy)\n","        step_losses.append(loss)\n","\n","    train_accuracies.append(np.mean(step_accuracies))\n","    train_losses.append(np.mean(step_losses))\n","    epoch_bar.set_postfix({\n","        'train loss': train_losses[-1],\n","        'train accuracy': train_accuracies[-1]\n","    })\n","\n","print(\"Training complete.\")\n","\n","# Evaluate the model at the end of training\n","total = len(test_images)\n","for i in range(0, total, batch_size):\n","    batch_images = test_images[i:i + batch_size]\n","    batch_labels = test_labels[i:i + batch_size].astype(int)\n","\n","    output = mlp.forward(batch_images)\n","    predictions = np.argmax(output, axis=1)\n","    correct += np.sum(predictions == batch_labels)\n","\n","test_accuracy = correct / total\n","print(f\"Test accuracy: {test_accuracy:.2%}\")"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"25YyuDfA53aJ","tags":[]},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1200x400 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# plot training curves\n","fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n","\n","axes[0].plot(\n","    np.arange(1, epochs+1),\n","    train_losses,\n","    color='blue'\n",")\n","axes[0].set_title('Training loss')\n","axes[0].set_xlabel('Epoch')\n","axes[0].set_ylabel('Loss')\n","axes[0].grid()\n","\n","axes[1].plot(\n","    np.arange(1, epochs+1),\n","    train_accuracies,\n","    color='red'\n",")\n","axes[1].set_title('Training accuracy')\n","axes[1].set_xlabel('Epoch')\n","axes[1].set_ylabel('Accuracy')\n","axes[1].grid()\n","\n","axes[0].set_xticks(range(0, epochs+1, 2))\n","axes[1].set_xticks(range(0, epochs+1, 2))\n","fig.tight_layout()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"5CkWpkFe6NVk"},"source":["<!-- END QUESTION -->\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}
